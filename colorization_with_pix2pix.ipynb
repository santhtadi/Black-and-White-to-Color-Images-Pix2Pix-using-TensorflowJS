{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colorization with pix2pix.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEUAVpIV4UtU"
      },
      "source": [
        "# Contents\n",
        "##1. Collect Data\n",
        "##2. Prepare dataset (input-output - 256x256 each)\n",
        "##3. Clone Pix2Pix Repo\n",
        "##4. Train Model\n",
        "##5. Export Model\n",
        "##6. Convert Model to tfjs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-tmr9_X4jiw"
      },
      "source": [
        "#1. Collect Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fr39h5P4vCI"
      },
      "source": [
        "I used the **ffhq dataset** available at https://github.com/NVlabs/ffhq-dataset\n",
        "\n",
        "It is available under [Creative Commons BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NCFtdrm5TCE"
      },
      "source": [
        "**Paper Citation:**\n",
        "\n",
        ">A Style-Based Generator Architecture for Generative Adversarial Networks\n",
        "Tero Karras (NVIDIA), Samuli Laine (NVIDIA), Timo Aila (NVIDIA)\n",
        "https://arxiv.org/abs/1812.04948"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJTq-W_83a77"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI-sYQqu50s_"
      },
      "source": [
        "#2. Prepare Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDQ230xX6FP5"
      },
      "source": [
        "## 2.1 Upload and unzip data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fNa9aXJDaku"
      },
      "source": [
        "!cp drive/MyDrive/colorization/38000.zip ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZTj6GTR5_wp"
      },
      "source": [
        "!unzip 38000.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9njTo-Bz6Iii"
      },
      "source": [
        "## 2.2 Resize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfCro_SU6RyS"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57HVF3hf6ela"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvC3v5NL6S6L"
      },
      "source": [
        "all_images = [image_name for image_name in os.listdir(\"./38000\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0Z-FxvK6ogs"
      },
      "source": [
        "os.mkdir(\"dataset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6hq6s-V64og"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PywWqTMV85bl"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL30IKSn6gw4",
        "outputId": "dad4d867-3c6d-49f6-abde-c7d82f8e3d12"
      },
      "source": [
        "for image_name in tqdm(all_images):\n",
        "  img = cv2.imread(\"./38000/%s\"%image_name)\n",
        "  img = cv2.resize(img, (256, 256))\n",
        "  img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  img_gray = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n",
        "  img_dataset = np.hstack([img_gray, img])\n",
        "  cv2.imwrite(\"./dataset/%s\"%image_name, img_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:08<00:00, 118.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbXI8u4j-ZNW"
      },
      "source": [
        "# 3. Clone Pix2Pix Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw6Cl94L-eaA"
      },
      "source": [
        "## Huge thanks to https://github.com/yining1023/pix2pix_tensorflowjs_lite and https://github.com/affinelayer/pix2pix-tensorflow repos for the detailed explanation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVYD3lyU8vOc",
        "outputId": "3e984e26-7760-436c-9378-ff76262495d6"
      },
      "source": [
        "!git clone https://github.com/affinelayer/pix2pix-tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pix2pix-tensorflow'...\n",
            "remote: Enumerating objects: 261, done.\u001b[K\n",
            "remote: Total 261 (delta 0), reused 0 (delta 0), pack-reused 261\u001b[K\n",
            "Receiving objects: 100% (261/261), 13.33 MiB | 24.86 MiB/s, done.\n",
            "Resolving deltas: 100% (103/103), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FDE4wNR-7K6",
        "outputId": "908025ac-09ff-4082-87b7-aa4c09c267c3"
      },
      "source": [
        "%cd pix2pix-tensorflow/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pix2pix-tensorflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieuuxE90--sn",
        "outputId": "623233e2-bb5f-4a73-d83c-ce60ca9c0d0d"
      },
      "source": [
        "%%shell\n",
        "mkdir -p photos/combined"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujqh0oXl-ccu",
        "outputId": "d46b409e-618b-4fdc-e435-4196593a5d18"
      },
      "source": [
        "%%shell\n",
        "cp ../dataset/* photos/combined/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRFcQjZg_fEm"
      },
      "source": [
        "#4. Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clmymX0Q_mN1"
      },
      "source": [
        "##4.1 Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nigFhPd_ld8"
      },
      "source": [
        "%%shell\n",
        "python tools/split.py --dir photos/combined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr-bltTf_xs2"
      },
      "source": [
        "##4.2 Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF03maJMAnXH",
        "outputId": "0d3a8f99-ebf4-42f4-e8c5-026d260ad06f"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "## Replace 'import tensorflow as tf' with these two lines in pix2pix.py if you face any errors with the next line"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5QNl4e0_JQh"
      },
      "source": [
        "%%shell\n",
        "python pix2pix.py --mode train --output_dir colorized_train --max_epochs 200 --input_dir photos/combined/train --which_direction AtoB --ngf 32 --ndf 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UJvVbVWIdfg"
      },
      "source": [
        "%%shell\n",
        "python pix2pix.py --mode test --output_dir pikachu_test --input_dir photos/combined/val --checkpoint colorized_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a1tvGkDNtnw"
      },
      "source": [
        "#5. Export checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojCqNMfSBdK4",
        "outputId": "fb21777b-43ce-4a8f-ac2b-aba28d9b8590"
      },
      "source": [
        "%%shell\n",
        "python pix2pix.py --mode export --output_dir ./export/ --checkpoint ./colorized_train/ --which_direction AtoB"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "loaded lab_colorization = False\n",
            "loaded ndf = 32\n",
            "loaded ngf = 32\n",
            "loaded which_direction = AtoB\n",
            "aspect_ratio = 1.0\n",
            "batch_size = 1\n",
            "beta1 = 0.5\n",
            "checkpoint = ./colorized_train/\n",
            "display_freq = 0\n",
            "flip = False\n",
            "gan_weight = 1.0\n",
            "input_dir = None\n",
            "l1_weight = 100.0\n",
            "lab_colorization = False\n",
            "lr = 0.0002\n",
            "max_epochs = None\n",
            "max_steps = None\n",
            "mode = export\n",
            "ndf = 32\n",
            "ngf = 32\n",
            "output_dir = ./export/\n",
            "output_filetype = png\n",
            "progress_freq = 50\n",
            "save_freq = 5000\n",
            "scale_size = 256\n",
            "seed = 707106167\n",
            "separable_conv = False\n",
            "summary_freq = 100\n",
            "trace_freq = 0\n",
            "which_direction = AtoB\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/convolutional.py:536: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1676: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/normalization.py:424: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  '`tf.layers.batch_normalization` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/convolutional.py:1660: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "  warnings.warn('`tf.layers.conv2d_transpose` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "2021-09-30 10:01:46.813051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-30 10:01:46.823143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-30 10:01:46.824008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-30 10:01:46.825486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-30 10:01:46.826377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-30 10:01:46.827230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-30 10:01:47.344218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-30 10:01:47.345117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-30 10:01:47.345933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-30 10:01:47.346653: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-09-30 10:01:47.346723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10819 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
            "loading model from checkpoint\n",
            "exporting model\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHHSguv0Nw5R"
      },
      "source": [
        "#6. Convert to Tensorflow JS model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wLOM4byNUSU"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "## Replace 'import tensorflow as tf' with these two lines in server/tools/dump_checkpoints/tensorflow_checkpoint_dumper.py if you face any errors with the next line"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPsvAg2sJahQ",
        "outputId": "a35850f7-5f35-4e6c-e5b6-c88bbad62967"
      },
      "source": [
        "%%shell\n",
        "cd server\n",
        "mkdir -p ./static/models\n",
        "python tools/export-checkpoint.py --checkpoint ../export --output_file ./static/models/colorized_AtoB.pict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Writing variable generator/encoder_8/conv2d/bias...\n",
            "Writing variable generator/encoder_8/batch_normalization/moving_variance...\n",
            "Writing variable generator/encoder_8/batch_normalization/moving_mean...\n",
            "Writing variable generator/encoder_8/batch_normalization/gamma...\n",
            "Writing variable generator/encoder_8/batch_normalization/beta...\n",
            "Writing variable generator/encoder_7/conv2d/kernel...\n",
            "Writing variable generator/encoder_7/conv2d/bias...\n",
            "Writing variable generator/encoder_7/batch_normalization/moving_variance...\n",
            "Writing variable generator/decoder_4/conv2d_transpose/kernel...\n",
            "Writing variable generator/decoder_7/batch_normalization/moving_mean...\n",
            "Writing variable generator/encoder_6/conv2d/bias...\n",
            "Writing variable generator/decoder_7/batch_normalization/gamma...\n",
            "Writing variable generator/decoder_6/batch_normalization/moving_mean...\n",
            "Writing variable generator/decoder_7/batch_normalization/beta...\n",
            "Writing variable generator/decoder_7/conv2d_transpose/bias...\n",
            "Writing variable generator/decoder_6/batch_normalization/beta...\n",
            "Writing variable generator/decoder_5/batch_normalization/moving_variance...\n",
            "Writing variable generator/encoder_1/conv2d/bias...\n",
            "Writing variable generator/decoder_3/conv2d_transpose/bias...\n",
            "Writing variable generator/decoder_4/conv2d_transpose/bias...\n",
            "Writing variable generator/decoder_5/conv2d_transpose/kernel...\n",
            "Writing variable generator/decoder_6/conv2d_transpose/kernel...\n",
            "Writing variable generator/decoder_4/batch_normalization/moving_variance...\n",
            "Writing variable generator/decoder_2/batch_normalization/moving_variance...\n",
            "Writing variable generator/decoder_2/batch_normalization/gamma...\n",
            "Writing variable generator/decoder_3/batch_normalization/beta...\n",
            "Writing variable generator/decoder_3/batch_normalization/gamma...\n",
            "Writing variable generator/decoder_2/batch_normalization/beta...\n",
            "Writing variable generator/decoder_1/conv2d_transpose/kernel...\n",
            "Writing variable generator/decoder_6/batch_normalization/gamma...\n",
            "Writing variable generator/decoder_4/batch_normalization/gamma...\n",
            "Writing variable generator/decoder_1/conv2d_transpose/bias...\n",
            "Writing variable generator/decoder_2/conv2d_transpose/bias...\n",
            "Writing variable generator/decoder_3/batch_normalization/moving_mean...\n",
            "Writing variable generator/encoder_3/batch_normalization/moving_mean...\n",
            "Writing variable generator/encoder_7/batch_normalization/moving_mean...\n",
            "Writing variable generator/decoder_2/conv2d_transpose/kernel...\n",
            "Writing variable generator/encoder_3/batch_normalization/beta...\n",
            "Writing variable generator/decoder_3/batch_normalization/moving_variance...\n",
            "Writing variable generator/decoder_5/conv2d_transpose/bias...\n",
            "Writing variable generator/decoder_6/batch_normalization/moving_variance...\n",
            "Writing variable generator/encoder_4/batch_normalization/moving_variance...\n",
            "Writing variable generator/decoder_5/batch_normalization/moving_mean...\n",
            "Writing variable generator/encoder_3/batch_normalization/gamma...\n",
            "Writing variable generator/decoder_3/conv2d_transpose/kernel...\n",
            "Writing variable generator/decoder_2/batch_normalization/moving_mean...\n",
            "Writing variable generator/decoder_8/conv2d_transpose/bias...\n",
            "Writing variable generator/encoder_7/batch_normalization/beta...\n",
            "Writing variable generator/decoder_4/batch_normalization/beta...\n",
            "Writing variable generator/decoder_7/conv2d_transpose/kernel...\n",
            "Writing variable generator/encoder_2/batch_normalization/moving_mean...\n",
            "Writing variable generator/decoder_8/batch_normalization/gamma...\n",
            "Writing variable generator/decoder_8/batch_normalization/moving_variance...\n",
            "Writing variable generator/decoder_8/conv2d_transpose/kernel...\n",
            "Writing variable generator/encoder_1/conv2d/kernel...\n",
            "Writing variable generator/decoder_5/batch_normalization/gamma...\n",
            "Writing variable generator/decoder_8/batch_normalization/moving_mean...\n",
            "Writing variable generator/encoder_2/batch_normalization/gamma...\n",
            "Writing variable generator/encoder_2/batch_normalization/moving_variance...\n",
            "Writing variable generator/decoder_4/batch_normalization/moving_mean...\n",
            "Writing variable generator/encoder_2/conv2d/kernel...\n",
            "Writing variable generator/decoder_8/batch_normalization/beta...\n",
            "Writing variable generator/encoder_4/batch_normalization/gamma...\n",
            "Writing variable generator/encoder_3/batch_normalization/moving_variance...\n",
            "Writing variable generator/encoder_2/batch_normalization/beta...\n",
            "Writing variable generator/encoder_4/conv2d/kernel...\n",
            "Writing variable generator/encoder_3/conv2d/bias...\n",
            "Writing variable generator/encoder_3/conv2d/kernel...\n",
            "Writing variable generator/encoder_2/conv2d/bias...\n",
            "Writing variable generator/encoder_4/batch_normalization/beta...\n",
            "Writing variable generator/decoder_6/conv2d_transpose/bias...\n",
            "Writing variable generator/encoder_4/conv2d/bias...\n",
            "Writing variable generator/encoder_6/batch_normalization/moving_mean...\n",
            "Writing variable generator/encoder_5/batch_normalization/beta...\n",
            "Writing variable generator/encoder_8/conv2d/kernel...\n",
            "Writing variable generator/encoder_6/batch_normalization/beta...\n",
            "Writing variable generator/encoder_5/batch_normalization/gamma...\n",
            "Writing variable generator/decoder_5/batch_normalization/beta...\n",
            "Writing variable generator/encoder_5/batch_normalization/moving_mean...\n",
            "Writing variable generator/encoder_5/batch_normalization/moving_variance...\n",
            "Writing variable generator/encoder_4/batch_normalization/moving_mean...\n",
            "Writing variable generator/encoder_5/conv2d/bias...\n",
            "Writing variable generator/encoder_5/conv2d/kernel...\n",
            "Writing variable generator/encoder_6/batch_normalization/gamma...\n",
            "Writing variable generator/decoder_7/batch_normalization/moving_variance...\n",
            "Writing variable generator/encoder_7/batch_normalization/gamma...\n",
            "Writing variable generator/encoder_6/batch_normalization/moving_variance...\n",
            "Writing variable generator/encoder_6/conv2d/kernel...\n",
            "Writing manifest to /tmp/tmpy9848m76/manifest.json\n",
            "index found in 0.37s\n",
            "quantizing\n",
            "rate 169478\n",
            "rate 174536\n",
            "rate 176802\n",
            "rate 177885\n",
            "rate 178490\n",
            "rate 178906\n",
            "rate 179546\n",
            "rate 180068\n",
            "rate 180646\n",
            "rate 181033\n",
            "rate 181250\n",
            "rate 181582\n",
            "rate 181817\n",
            "shape bytes 6701\n",
            "index bytes 1024\n",
            "encoded bytes 13616963\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PLDb8vIKDg5",
        "outputId": "e4c4e8fa-1a3c-42b8-98d9-8ec0339a0c1c"
      },
      "source": [
        "%%shell\n",
        "cp server/static/models/colorized_AtoB.pict /content/drive/MyDrive/colorization/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7GoaC1uMaoX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}